{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './run_time_record'\n",
    "EXPECTED_FILES = 26\n",
    "\n",
    "# 1. Collect JSON files and assert count\n",
    "json_files = sorted(f for f in os.listdir(BASE_DIR) if f.endswith('.json'))\n",
    "assert len(json_files) == EXPECTED_FILES, f\"Expected {EXPECTED_FILES} JSON files, found {len(json_files)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_times(filepath):\n",
    "    data = json.load(open(filepath, 'r', encoding='utf-8'))\n",
    "    # Single-entry times\n",
    "    const_t = data['const-var-time']['runTime']\n",
    "    action_t = data['action-time']['runTime']\n",
    "    nl_t = data['nl-annotation-time']['runTime']\n",
    "    # Multi-entry\n",
    "    codegen = [v['runTime'] for k,v in data.items() if k.startswith('codegen-time_')]\n",
    "    verify  = [v['runTime'] for k,v in data.items() if k.startswith('verification-time_')]\n",
    "    refine  = [(int(k.split('_')[1]), v['runTime'])\n",
    "               for k,v in data.items() if k.startswith('refine-time_')]\n",
    "    # Stats\n",
    "    n_cg = len(codegen)\n",
    "    tot_cg = sum(codegen)\n",
    "    avg_cg = tot_cg / n_cg if n_cg else 0.0\n",
    "    rounds = [i for i,_ in refine]\n",
    "    tot_rounds = max(rounds) if rounds else 0\n",
    "    attempts = len(refine)\n",
    "    tot_ref_t = sum(t for _,t in refine)\n",
    "    avg_ref_t = tot_ref_t / attempts if attempts else 0.0\n",
    "    n_v = len(verify)\n",
    "    tot_v = sum(verify)\n",
    "    avg_v = tot_v / n_v if n_v else 0.0\n",
    "    return {\n",
    "        'const_var_time': const_t,\n",
    "        'action_time': action_t,\n",
    "        'nl_annotation_time': nl_t,\n",
    "        'num_codegen': n_cg,\n",
    "        'total_codegen_time': tot_cg,\n",
    "        'avg_codegen_time': avg_cg,\n",
    "        'total_refine_rounds': tot_rounds,\n",
    "        'total_refine_attempts': attempts,\n",
    "        'total_refine_time': tot_ref_t,\n",
    "        'avg_refine_time': avg_ref_t,\n",
    "        'num_verifications': n_v,\n",
    "        'total_verif_time': tot_v,\n",
    "        'avg_verif_time': avg_v\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build per-system DataFrame\n",
    "records = []\n",
    "for fname in json_files:\n",
    "    sys = os.path.splitext(fname)[0]\n",
    "    stats = parse_times(os.path.join(BASE_DIR, fname))\n",
    "    stats['system'] = sys\n",
    "    records.append(stats)\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Compute overall averages\n",
    "overall = df.mean(numeric_only=True).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a) Compute detailed summary stats for all time columns\n",
    "time_cols = [\n",
    "    'const_var_time',\n",
    "    'action_time',\n",
    "    'nl_annotation_time',\n",
    "    'total_codegen_time',\n",
    "    'avg_codegen_time',\n",
    "    'total_refine_time',\n",
    "    'avg_refine_time',\n",
    "    'total_verif_time',\n",
    "    'avg_verif_time'\n",
    "]\n",
    "\n",
    "# describe gives min, 25%, 50%, 75%, max, mean, std\n",
    "detailed_stats = (\n",
    "    df[time_cols]\n",
    "      .describe(percentiles=[0.25, 0.5, 0.75])\n",
    "      .T\n",
    "      .loc[:, ['min','25%','50%','75%','max','mean','std']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b) Then in your ExcelWriter block, dump it to its own sheet\n",
    "with pd.ExcelWriter('time_summary.xlsx', engine='xlsxwriter') as writer:\n",
    "    df.to_excel(writer, sheet_name='PerSystem', index=False)\n",
    "    overall.to_excel(writer, sheet_name='Averages', index=False)\n",
    "    detailed_stats.to_excel(writer, sheet_name='TimeDistributions')\n",
    "\n",
    "print(\"âœ…  Saved time_summary.xlsx with sheets 'PerSystem', 'Averages', and 'TimeDistributions'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
